{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e6960bb-cb7b-4544-8731-aedf4f21a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data_loc = '/Users/Sage/PycharmProjects/Data-Projects/Coffee FlavorsxOrigin/data/coffee_data.json'\n",
    "\n",
    "def load_data(data_loc, data):\n",
    "    with open(data_loc, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "            \n",
    "\n",
    "def save_data(data):\n",
    "    with open(data_loc, 'w') as outfile:\n",
    "        json.dump(data, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950155f7-8d35-4ca4-850f-dd410eeafd9e",
   "metadata": {},
   "source": [
    "Let's start by doing some light data cleaning leading into some light EDA. \n",
    "This will be done by taking a look at the scraped coffee names and inserting country data into the data JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faae164c-c97d-4d56-8683-340d302beb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_loc, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37a9b2a1-1e84-458a-8177-109edf30b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [x.split()[0] for x in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8c8a567-c46d-42e7-a0df-c367337d63c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java',\n",
       " 'Flores',\n",
       " 'Guatemala',\n",
       " 'Papua',\n",
       " 'Roasted',\n",
       " 'Indonesia',\n",
       " 'Sumatra',\n",
       " 'El',\n",
       " 'Espresso',\n",
       " 'Yemen',\n",
       " 'Colombia',\n",
       " 'Brazil',\n",
       " 'Zambia',\n",
       " 'Winter',\n",
       " 'Sulawesi',\n",
       " 'Timor',\n",
       " 'Timorindo',\n",
       " 'India',\n",
       " 'Congo',\n",
       " 'Panama',\n",
       " 'ROASTED',\n",
       " 'Tanzania',\n",
       " 'Cameroon',\n",
       " 'Nicaragua',\n",
       " 'Burundi',\n",
       " 'Peru',\n",
       " 'Sweet',\n",
       " 'Ethiopia',\n",
       " 'Rwanda',\n",
       " 'Costa',\n",
       " 'Kenya',\n",
       " 'Mexico',\n",
       " 'Honduras']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = list(set(countries))\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132af429-e9b0-4e1c-bc12-c7c3185d18f6",
   "metadata": {},
   "source": [
    "Since this list of distinct first words mostly contains countries (with a few issues), the next step is to clean up this list so we can insert the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb831d62-7b74-4448-9384-ff5d56e16b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [x for x in countries if x not in ('ROASTED', 'Sweet', 'Winter','Roasted')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0428810-ae09-4468-a6bf-5d42c7436cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.append('El Salvador')\n",
    "countries.remove('El')\n",
    "countries.append('Costa Rica')\n",
    "countries.remove('Costa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cc7774e-f99b-43ac-bdac-c9b586d83d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java', 'Flores', 'Guatemala', 'Papua', 'Indonesia', 'Sumatra', 'Espresso', 'Yemen', 'Colombia', 'Brazil', 'Zambia', 'Sulawesi', 'Timor', 'Timorindo', 'India', 'Congo', 'Panama', 'Tanzania', 'Cameroon', 'Nicaragua', 'Burundi', 'Peru', 'Ethiopia', 'Rwanda', 'Kenya', 'Mexico', 'Honduras', 'El Salvador', 'Costa Rica']\n"
     ]
    }
   ],
   "source": [
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb5c0a-3750-42a0-ba6b-02efcfa5bbc7",
   "metadata": {},
   "source": [
    "Looks much better. Next step is to insert these into each document where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "260a35e6-7250-4a2b-99b1-3f962c81498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    country_guess = k.split()[:2]\n",
    "    \n",
    "    if country_guess[0] in countries:\n",
    "        v['origin'] = country_guess[0]\n",
    "    elif (new_guess := ' '.join(country_guess)) in countries:\n",
    "        v['origin'] = new_guess\n",
    "    else:\n",
    "        v['origin'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3857d10b-ad91-48b8-b27c-cdf9dd74de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil', 'Burundi', 'Cameroon', 'Colombia', 'Congo', 'Costa Rica', 'El Salvador', 'Espresso', 'Ethiopia', 'Flores', 'Guatemala', 'Honduras', 'India', 'Indonesia', 'Java', 'Kenya', 'Mexico', 'Nicaragua', 'Panama', 'Papua', 'Peru', None, 'Rwanda', 'Sulawesi', 'Sumatra', 'Tanzania', 'Timor', 'Timorindo', 'Yemen', 'Zambia']\n"
     ]
    }
   ],
   "source": [
    "origins = []\n",
    "for k, v in data.items():\n",
    "    if v['origin'] not in origins:\n",
    "        origins.append(v['origin'])\n",
    "print(origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42e562-5066-4407-ab8e-951156c3ebb3",
   "metadata": {},
   "source": [
    "Looks good. Let's take a look at those None values and see if there is anything we can do about them at this time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31a8a619-b91b-43e2-8eb4-31ca8cc4da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweet Maria's Ethiopiques Version 2.0\n",
      "Sweet Maria's Half-Caff Blend\n",
      "Sweet Maria's Moka Java SWP Decaf Blend\n",
      "Sweet Maria's Moka Kadir Blend\n",
      "Sweet Maria's Polar Expresso Holiday Blend\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    if v['origin'] is None:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ffece0-66a0-44c2-8902-6b3b585bfce8",
   "metadata": {},
   "source": [
    "Since we are specifically looking at green coffees, not roasted coffees, let's remove the 5 roasted entires from the dataset. We also already have an Ethiopia Honey Genji entry, so we can delete that as well.\n",
    "\n",
    "We can leave the Sweet Maria's blend coffees with a None value for the origin, so we only need to manually deal with the Winter Special entry and the espresso workshop entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fc88d97-fa4d-49cf-8d02-9b070f5b51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['ROASTED COFFEE El Salvador Apaneca Finca Miravalle']\n",
    "del data['ROASTED COFFEE Zambia Dry Process Kateshi Estate ']\n",
    "del data['ROASTED ESPRESSO Liquid Amber Blend']\n",
    "del data['ROASTED ESPRESSO Workshop The Skullet']\n",
    "del data['Roasted Coffee Subscription']\n",
    "del data['Winter Special: Ethiopia Honey Genji']\n",
    "del data['Espresso Workshop #49 Balayage']\n",
    "del data['Espresso Workshop #50 - The Skullet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54119712-bc4d-4f60-b300-ade71e86504c",
   "metadata": {},
   "source": [
    "Next, let's create a boolean value for Decaf in case we need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9492bb6-ed27-4ae7-a88f-24da0f195525",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    if 'Decaf' in k:\n",
    "        v['decaf'] = True\n",
    "    else:\n",
    "        v['decaf'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3e40a-b83a-417d-98ae-18731c7d224d",
   "metadata": {},
   "source": [
    "Finally, let's save the data and start looking into cupping and flavor scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dca3a1b4-5f44-4196-bc16-7a807a4e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
