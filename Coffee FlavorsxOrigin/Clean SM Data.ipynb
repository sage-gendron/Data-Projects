{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e6960bb-cb7b-4544-8731-aedf4f21a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data_loc = '/Users/Sage/PycharmProjects/Data-Projects/Coffee FlavorsxOrigin/data/coffee_data.json'\n",
    "\n",
    "def load_data(data_loc, data):\n",
    "    with open(data_loc, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "            \n",
    "\n",
    "def save_data(data):\n",
    "    with open(data_loc, 'w') as outfile:\n",
    "        json.dump(data, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6298ab2-1ee4-49a5-ae33-1c3e980eb960",
   "metadata": {},
   "source": [
    "Let's start by doing some light data cleaning leading into some light EDA. \n",
    "This will be done by taking a look at the scraped coffee names and inserting country data into the data JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faae164c-c97d-4d56-8683-340d302beb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_loc, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37a9b2a1-1e84-458a-8177-109edf30b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [x.split()[0] for x in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8c8a567-c46d-42e7-a0df-c367337d63c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java',\n",
       " 'Flores',\n",
       " 'Guatemala',\n",
       " 'Papua',\n",
       " 'Roasted',\n",
       " 'Indonesia',\n",
       " 'Sumatra',\n",
       " 'El',\n",
       " 'Espresso',\n",
       " 'Yemen',\n",
       " 'Colombia',\n",
       " 'Brazil',\n",
       " 'Zambia',\n",
       " 'Winter',\n",
       " 'Sulawesi',\n",
       " 'Timor',\n",
       " 'Timorindo',\n",
       " 'India',\n",
       " 'Congo',\n",
       " 'Panama',\n",
       " 'ROASTED',\n",
       " 'Tanzania',\n",
       " 'Cameroon',\n",
       " 'Nicaragua',\n",
       " 'Burundi',\n",
       " 'Peru',\n",
       " 'Sweet',\n",
       " 'Ethiopia',\n",
       " 'Rwanda',\n",
       " 'Costa',\n",
       " 'Kenya',\n",
       " 'Mexico',\n",
       " 'Honduras']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = list(set(countries))\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132af429-e9b0-4e1c-bc12-c7c3185d18f6",
   "metadata": {},
   "source": [
    "Since this list of distinct first words mostly contains countries (with a few issues), the next step is to clean up this list so we can insert the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb831d62-7b74-4448-9384-ff5d56e16b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [x for x in countries if x not in ('ROASTED', 'Sweet', 'Winter','Roasted')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0428810-ae09-4468-a6bf-5d42c7436cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.append('El Salvador')\n",
    "countries.remove('El')\n",
    "countries.append('Costa Rica')\n",
    "countries.remove('Costa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cc7774e-f99b-43ac-bdac-c9b586d83d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java', 'Flores', 'Guatemala', 'Papua', 'Indonesia', 'Sumatra', 'Espresso', 'Yemen', 'Colombia', 'Brazil', 'Zambia', 'Sulawesi', 'Timor', 'Timorindo', 'India', 'Congo', 'Panama', 'Tanzania', 'Cameroon', 'Nicaragua', 'Burundi', 'Peru', 'Ethiopia', 'Rwanda', 'Kenya', 'Mexico', 'Honduras', 'El Salvador', 'Costa Rica']\n"
     ]
    }
   ],
   "source": [
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb5c0a-3750-42a0-ba6b-02efcfa5bbc7",
   "metadata": {},
   "source": [
    "Looks much better. Next step is to insert these into each document where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "260a35e6-7250-4a2b-99b1-3f962c81498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    country_guess = k.split()[:2]\n",
    "    \n",
    "    if country_guess[0] in countries:\n",
    "        v['origin'] = country_guess[0]\n",
    "    elif (new_guess := ' '.join(country_guess)) in countries:\n",
    "        v['origin'] = new_guess\n",
    "    else:\n",
    "        v['origin'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3857d10b-ad91-48b8-b27c-cdf9dd74de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil', 'Burundi', 'Cameroon', 'Colombia', 'Congo', 'Costa Rica', 'El Salvador', 'Espresso', 'Ethiopia', 'Flores', 'Guatemala', 'Honduras', 'India', 'Indonesia', 'Java', 'Kenya', 'Mexico', 'Nicaragua', 'Panama', 'Papua', 'Peru', None, 'Rwanda', 'Sulawesi', 'Sumatra', 'Tanzania', 'Timor', 'Timorindo', 'Yemen', 'Zambia']\n"
     ]
    }
   ],
   "source": [
    "origins = []\n",
    "for k, v in data.items():\n",
    "    if v['origin'] not in origins:\n",
    "        origins.append(v['origin'])\n",
    "print(origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42e562-5066-4407-ab8e-951156c3ebb3",
   "metadata": {},
   "source": [
    "Looks good. Let's take a look at those None values and see if there is anything we can do about them at this time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31a8a619-b91b-43e2-8eb4-31ca8cc4da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROASTED COFFEE El Salvador Apaneca Finca Miravalle\n",
      "ROASTED COFFEE Zambia Dry Process Kateshi Estate \n",
      "ROASTED ESPRESSO Liquid Amber Blend\n",
      "ROASTED ESPRESSO Workshop The Skullet\n",
      "Roasted Coffee Subscription\n",
      "Sweet Maria's Ethiopiques Version 2.0\n",
      "Sweet Maria's Half-Caff Blend\n",
      "Sweet Maria's Moka Java SWP Decaf Blend\n",
      "Sweet Maria's Moka Kadir Blend\n",
      "Sweet Maria's Polar Expresso Holiday Blend\n",
      "Winter Special: Ethiopia Honey Genji\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    if v['origin'] is None:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54119712-bc4d-4f60-b300-ade71e86504c",
   "metadata": {},
   "source": [
    "Let's also create a boolean value for Decaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9492bb6-ed27-4ae7-a88f-24da0f195525",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    if 'Decaf' in k:\n",
    "        v['decaf'] = True\n",
    "    else:\n",
    "        v['decaf'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dca3a1b4-5f44-4196-bc16-7a807a4e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b2de4-c5fd-42c9-9783-0cc208746e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
